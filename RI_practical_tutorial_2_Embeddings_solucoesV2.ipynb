{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5UNiVMANe3SINKBbWu9lf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ua-deti-information-retrieval/Neural-IR-hands-on/blob/main/RI_practical_tutorial_2_Embeddings_solucoesV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RI practical tutorial #2\n",
        "\n",
        "## Embeddings\n",
        "\n",
        "An important component of natural language processing (NLP) is the ability to translate words, phrases, or larger bodies of text into continuous numerical vectors.\n",
        "\n"
      ],
      "metadata": {
        "id": "WEzDVxR_GS_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies"
      ],
      "metadata": {
        "id": "HTM0S306OL5a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7KLH66SGHFk",
        "outputId": "f878fc22-ce2c-418d-f71b-3f0f97243809"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "fatal: destination path 'Neural-IR-hands-on' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!pip install torch matplotlib\n",
        "!git clone https://github.com/ua-deti-information-retrieval/Neural-IR-hands-on.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "E5CGinJe1IBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Recap\n",
        "\n",
        "Embeddings convert words, sentences, or even entire documents into vectors of real numbers. Unlike traditional methods like one-hot encoding, which represent words as isolated and high-dimensional points."
      ],
      "metadata": {
        "id": "HnYRQPKWORgd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# the -> 0\n",
        "# supreme -> 1\n",
        "# art -> 5\n",
        "# 015\n",
        "\n",
        "\n",
        "toy_vocab = ['the','supreme','art','of','war','is','to','subdue','the','enemy','without','fighting'] # 123\n",
        "torch.eye(len(toy_vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FWQGAEJAlMX3",
        "outputId": "ff4209de-813b-4a82-eb3e-16362b5b5b31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
              "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_layer = torch.nn.Embedding(len(toy_vocab), 4) # lookup table\n",
        "print(embedding_layer.weight)\n",
        "print(\"embeddings norm\", torch.linalg.norm(embedding_layer.weight, ord=2, dim=-1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ApSIqDxl2BDt",
        "outputId": "9a7cbb6c-76f6-4314-8f8f-fe9785bf0427"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-0.9652, -0.0183, -0.7884,  0.4117],\n",
            "        [ 0.2808,  1.2251,  1.5657, -0.1117],\n",
            "        [-0.5183,  0.1446,  1.4250,  0.3445],\n",
            "        [ 0.3087, -1.5000, -0.7432,  1.4683],\n",
            "        [ 0.3633, -0.9857, -1.6775,  0.0584],\n",
            "        [ 0.0558,  1.3720,  0.5216, -1.8075],\n",
            "        [ 0.2945, -0.4124,  0.7072, -0.9646],\n",
            "        [-1.5088,  0.8306,  0.2767,  2.8368],\n",
            "        [-0.4752, -0.1008, -0.6639, -0.1164],\n",
            "        [-0.2077, -1.0223, -0.0475,  0.2471],\n",
            "        [-0.5356, -0.0821, -2.3560,  1.4714],\n",
            "        [ 1.7639, -0.9144, -1.1769, -0.1801]], requires_grad=True)\n",
            "embeddings norm tensor([1.3127, 2.0109, 1.5617, 2.2480, 1.9802, 2.3291, 1.2990, 3.3303, 0.8308,\n",
            "        1.0731, 2.8300, 2.3163], grad_fn=<LinalgVectorNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Hands on\n",
        "\n",
        "To get started with practical exercises in embeddings, it's beneficial to use pre-trained models. This allows us to explore and understand the power of embeddings without the need for extensive computational resources and time to train our models.\n",
        "\n",
        "For our exercise, we will use the DESM (Dual Embedding Space Model) from Microsoft (the same introduced in class). DESM is a unique model that leverages two types of embeddings."
      ],
      "metadata": {
        "id": "m8iWJcDj2y6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# run to download the desm embeddings\n",
        "!wget https://download.microsoft.com/download/A/7/C/A7C7F0A6-B925-4C07-A14B-04ACF8A8E030/desm.zip\n",
        "!unzip desm.zip"
      ],
      "metadata": {
        "id": "zbztb3qROK9i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add622cd-99a6-4e8a-aab4-7e86030d3fa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-30 13:58:25--  https://download.microsoft.com/download/A/7/C/A7C7F0A6-B925-4C07-A14B-04ACF8A8E030/desm.zip\n",
            "Resolving download.microsoft.com (download.microsoft.com)... 23.199.49.187, 2600:1408:c400:e8e::317f, 2600:1408:c400:e8c::317f\n",
            "Connecting to download.microsoft.com (download.microsoft.com)|23.199.49.187|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3757822502 (3.5G) [application/octet-stream]\n",
            "Saving to: ‘desm.zip’\n",
            "\n",
            "desm.zip            100%[===================>]   3.50G   134MB/s    in 35s     \n",
            "\n",
            "2023-11-30 13:59:01 (102 MB/s) - ‘desm.zip’ saved [3757822502/3757822502]\n",
            "\n",
            "Archive:  desm.zip\n",
            "  inflating: in.txt                  \n",
            "  inflating: out.txt                 \n",
            "  inflating: README.txt              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/dwyl/english-words/master/words_alpha.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHyUI9cx79yM",
        "outputId": "4e389c52-1b28-499b-96dc-33c511001f37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-30 14:53:02--  https://raw.githubusercontent.com/dwyl/english-words/master/words_alpha.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4234917 (4.0M) [text/plain]\n",
            "Saving to: ‘words_alpha.txt’\n",
            "\n",
            "\rwords_alpha.txt       0%[                    ]       0  --.-KB/s               \rwords_alpha.txt     100%[===================>]   4.04M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-11-30 14:53:03 (205 MB/s) - ‘words_alpha.txt’ saved [4234917/4234917]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get a simple vocab, because load the in and out matrices will exaust the resources\n",
        "with open(\"words_alpha.txt\") as f:\n",
        "#with open(\"simple_vocab_example.txt\") as f:\n",
        "  vocab_set = {token.rstrip() for token in f}"
      ],
      "metadata": {
        "id": "rcM6NGyD-QxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_embeddings_from_txt(path, vocab):\n",
        "  emb = {}\n",
        "\n",
        "  with open(path) as f:\n",
        "    for line in tqdm(f):\n",
        "      token, *values = line.split(\"\\t\")\n",
        "      if token in vocab:\n",
        "        emb[token] = list(map(float, values))\n",
        "\n",
        "  # separating the vocab from the embeddings\n",
        "  vocab, embedding = list(zip(*emb.items()))\n",
        "  token_to_id = {token:i for i,token in enumerate(vocab)}\n",
        "  id_to_token = {v:k for k,v in token_to_id.items()}\n",
        "\n",
        "  return token_to_id, id_to_token, torch.tensor(embedding) # 173593x200\n",
        "\n",
        "in_token_to_id, in_id_to_token, in_embeddings = load_embeddings_from_txt(\"in.txt\", vocab_set)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj1C9OLV2fZI",
        "outputId": "fd019725-ceb1-4306-b7b2-6112a0d8521a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2748230it [01:17, 35470.37it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's explore the loaded embeddings.\n",
        "\n"
      ],
      "metadata": {
        "id": "acwoInucNeKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"shape\", in_embeddings.shape)\n",
        "nurse_id = in_token_to_id[\"nurse\"]\n",
        "print(\"Token: nurse | id:\", nurse_id)\n",
        "print(\"embeddings norm\", torch.linalg.norm(in_embeddings[nurse_id], ord=2)) #\n",
        "print(\"nurse embedding:\",in_embeddings[nurse_id])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_M_2gbU-P7l",
        "outputId": "681e9a3f-91a5-4da4-dd4d-82ff8fa38be9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape torch.Size([173593, 200])\n",
            "Token: nurse | id: 103266\n",
            "embeddings norm tensor(1.0000)\n",
            "nurse embedding: tensor([ 1.3924e-01, -9.9500e-04,  8.8700e-04,  6.8999e-02,  7.3316e-02,\n",
            "        -9.7289e-02, -5.1672e-02, -8.9405e-02,  8.8826e-02, -5.9428e-02,\n",
            "         1.3653e-02, -5.3968e-02,  5.9562e-02, -2.9867e-02,  1.0009e-01,\n",
            "        -1.9665e-02, -6.0743e-02, -9.9873e-02,  7.3166e-02,  1.6776e-01,\n",
            "        -8.6471e-02,  8.0610e-02,  1.5516e-02,  8.0300e-03,  1.6674e-01,\n",
            "        -1.2330e-03,  2.6245e-02,  4.9310e-03,  4.1719e-02, -3.9982e-02,\n",
            "         3.8725e-02, -1.3561e-01,  1.5320e-03, -1.0055e-02, -4.1976e-02,\n",
            "        -3.7175e-02,  6.5462e-02,  2.9214e-02,  4.2903e-02,  1.0753e-01,\n",
            "        -6.8870e-03, -4.3129e-02, -7.8007e-02, -8.1616e-02,  1.6278e-02,\n",
            "        -2.0872e-02,  1.3440e-01, -5.4099e-02, -3.3082e-02, -6.3098e-02,\n",
            "         6.8556e-02, -2.9421e-02, -1.0856e-01, -2.4650e-02,  1.0879e-02,\n",
            "        -3.0170e-03,  1.9260e-03,  8.4693e-02,  2.7450e-03, -9.0751e-02,\n",
            "        -2.6489e-02, -3.9880e-03, -6.8470e-03, -4.8287e-02, -9.4903e-02,\n",
            "        -3.3745e-02,  1.0264e-01,  5.3114e-02,  1.3562e-02, -2.7450e-03,\n",
            "        -8.1737e-02,  3.4620e-02,  1.0578e-01, -3.0848e-02,  1.3415e-02,\n",
            "        -1.4538e-02,  6.9535e-02,  5.9611e-02, -2.2465e-02, -1.0484e-01,\n",
            "         2.7590e-02, -1.1432e-01, -3.9521e-02, -5.2260e-03, -6.8681e-02,\n",
            "         7.9447e-02, -1.8811e-02, -3.0862e-02, -1.2629e-01,  1.4465e-02,\n",
            "         5.3159e-02,  1.9607e-02, -1.0353e-02, -4.8182e-02,  3.0883e-02,\n",
            "        -6.1812e-02,  6.9635e-02, -4.2391e-02, -4.7187e-02,  5.1619e-02,\n",
            "        -1.8270e-01,  3.9312e-02, -7.1090e-03, -1.0486e-02, -2.6453e-02,\n",
            "        -1.2696e-01,  6.9219e-02,  5.8230e-02,  3.6862e-02, -1.6258e-02,\n",
            "         1.1221e-01, -2.2389e-02, -3.3676e-02, -1.4977e-02, -4.7880e-02,\n",
            "         8.0119e-02, -1.3899e-01, -2.1125e-02,  2.8105e-02, -3.2037e-02,\n",
            "         9.6328e-02, -3.6039e-02,  8.0258e-02, -4.4169e-02, -9.3250e-03,\n",
            "         4.6607e-02, -1.2464e-01,  1.8522e-02, -3.9603e-02, -3.9038e-02,\n",
            "         5.9958e-02,  5.5145e-02,  1.2356e-01, -3.6805e-02, -1.1108e-01,\n",
            "         1.6796e-01, -1.7043e-01, -1.0241e-01, -8.7933e-02,  1.1613e-01,\n",
            "        -5.0390e-02, -6.4127e-02,  1.9350e-02, -1.8500e-04,  3.8157e-02,\n",
            "        -1.4333e-02, -2.2696e-02,  5.9196e-02,  1.0734e-01, -8.2128e-02,\n",
            "        -1.0073e-01, -6.7934e-02,  8.3090e-03, -8.9079e-02, -3.0541e-02,\n",
            "        -3.7274e-02, -3.3749e-02, -4.8042e-02, -2.2293e-02, -4.6589e-02,\n",
            "         1.8186e-02, -5.0126e-02,  2.5238e-02, -9.6308e-02,  2.0009e-02,\n",
            "        -5.2161e-02, -7.7058e-02,  9.2272e-02,  4.0024e-02, -1.8815e-01,\n",
            "         1.4271e-01,  1.4301e-02, -1.8410e-02,  4.1777e-02, -3.0649e-02,\n",
            "         4.0613e-02,  1.1409e-02, -3.8841e-02,  3.2464e-02, -1.4771e-01,\n",
            "        -2.5226e-02,  2.7110e-03, -7.0073e-02,  5.9491e-02,  4.4324e-02,\n",
            "        -2.3959e-02, -1.1435e-01, -3.5157e-02, -1.1848e-01, -1.2849e-01,\n",
            "        -7.5457e-02, -8.1210e-02,  8.1914e-02,  2.9619e-02, -2.0516e-01,\n",
            "         9.5400e-04, -2.4076e-02,  3.3285e-02, -5.5308e-02, -6.6755e-02])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to find similar tokens with embeddings?\n",
        "\n",
        "The same way you find similar vectors with tfidf, using cosine similarity!\n",
        "\n",
        "More precisely, given the two vectors:\n",
        "\n",
        "$cos(a,b) = \\frac{\\vec{a}\\cdot\\vec{b}^T}{\\|\\vec{a}\\|\\times\\|\\vec{b}\\|}$\n",
        "\n",
        "Then, we just need to compute the cosine similaraty between $\\vec{a}$ and all of the vectors in our matrix $C$ (collection).\n",
        "\n",
        "As an example, complete the following function. It should calculate the cosine similarity between a given vector and all the collection vectors and return the most similar tokens and scores."
      ],
      "metadata": {
        "id": "KR_RiWQcSenm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_topk_similar_to(token, embeddings, token_to_id, id_to_token, topk=10):\n",
        "  \"\"\"\n",
        "  Given the token return topk similar tokens according to the cos sim between the\n",
        "  token vector and all of the embeddings vectors\n",
        "  \"\"\"\n",
        "\n",
        "  token_embedding = embeddings[token_to_id[token]]\n",
        "  return find_topk_similar_to_vec(token_embedding, embeddings, token_to_id, id_to_token, topk)\n",
        "\n",
        "def find_topk_similar_to_vec(token_embedding, embeddings, token_to_id, id_to_token, topk=10):\n",
        "  \"\"\"\n",
        "  Given the token embedding return topk similar tokens according to the cos sim between the\n",
        "  token vector and all of the embeddings vectors\n",
        "\n",
        "\n",
        "  [('mercedes', 0.9999992251396179),\n",
        "  ('cabriolet', 0.6590193510055542),\n",
        "  ('sprinter', 0.6370120048522949),\n",
        "  ('volkswagen', 0.6347604393959045),\n",
        "  ('fiat', 0.6245887875556946),\n",
        "  ('jaguar', 0.6102705001831055),\n",
        "  ('toyota', 0.5901010632514954),\n",
        "  ('honda', 0.5850051641464233),\n",
        "  ('rover', 0.5818690061569214),\n",
        "  ('freightliner', 0.5783664584159851)]\n",
        "\n",
        "  \"\"\"\n",
        "  ## complete\n",
        "\n",
        "\n",
        "  # norm vector\n",
        "  #token_embedding = token_embedding / torch.linalg.norm(in_embeddings[nurse_id], ord=2)\n",
        "\n",
        "  # norm matrix\n",
        "  #embeddings = embeddings / torch.linalg.norm(embeddings, ord=2, dim=1, keepdim=True)\n",
        "\n",
        "\n",
        "\n",
        "  scores = embeddings @ token_embedding # 173593 X 200 @ 200 -> 173593\n",
        "\n",
        "  # O(nlog(n))\n",
        "\n",
        "  # O(nlog(k)) k<<n\n",
        "  ordered_scores, ordered_ids = torch.topk(scores, k=topk)\n",
        "\n",
        "  return list(map(lambda x: (id_to_token[x[0].item()], x[1].item()), zip(ordered_ids, ordered_scores)))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bQVkGG3KwWvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "find_topk_similar_to(\"yale\", in_embeddings, in_token_to_id, in_id_to_token)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2W8orRdyrUZ",
        "outputId": "d689ea19-75c2-4d2d-c84e-71acafc52476"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('yale', 1.0),\n",
              " ('harvard', 0.6379895210266113),\n",
              " ('cornell', 0.6104707717895508),\n",
              " ('quinnipiac', 0.6071730256080627),\n",
              " ('tufts', 0.5811516642570496),\n",
              " ('emory', 0.5635881423950195),\n",
              " ('hamline', 0.5511536002159119),\n",
              " ('stanford', 0.54926997423172),\n",
              " ('villanova', 0.5311557650566101),\n",
              " ('northwestern', 0.5205579400062561)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_topk_similar_to(\"apple\", in_embeddings, in_token_to_id, in_id_to_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RN4q_78tz9CO",
        "outputId": "bcf90b15-5e94-4da5-f81e-e99bc64a5e61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('apple', 1.0000005960464478),\n",
              " ('blackberry', 0.6527820825576782),\n",
              " ('apples', 0.611760139465332),\n",
              " ('mac', 0.5416128039360046),\n",
              " ('raspberry', 0.5347691178321838),\n",
              " ('cider', 0.52553391456604),\n",
              " ('chokecherry', 0.5230116844177246),\n",
              " ('blueberry', 0.49647897481918335),\n",
              " ('crouton', 0.4963668882846832),\n",
              " ('pumpkin', 0.494684100151062)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "find_topk_similar_to(\"oak\", in_embeddings, in_token_to_id, in_id_to_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5s44FRme_LQQ",
        "outputId": "ada65e45-7518-487e-e6d7-c79c770f7651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('oak', 1.0000003576278687),\n",
              " ('pine', 0.7786054015159607),\n",
              " ('walnut', 0.7469823360443115),\n",
              " ('maple', 0.7312123775482178),\n",
              " ('cedar', 0.7202832102775574),\n",
              " ('willow', 0.7179901003837585),\n",
              " ('birch', 0.7081882357597351),\n",
              " ('sycamore', 0.687503457069397),\n",
              " ('dogwood', 0.6859285235404968),\n",
              " ('hickory', 0.6843091249465942)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Why it works bad for covid? any guess?\n",
        "find_topk_similar_to(\"covid\", in_embeddings, in_token_to_id, in_id_to_token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uz_dCH2R_B3d",
        "outputId": "4e7cb04e-c91f-4db5-ba2d-886e333d0eb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('covid', 1.000001072883606),\n",
              " ('tensometer', 0.5409350395202637),\n",
              " ('shakeproof', 0.5386678576469421),\n",
              " ('hariana', 0.5289627313613892),\n",
              " ('outmatch', 0.5276938676834106),\n",
              " ('abattis', 0.5260857939720154),\n",
              " ('stobbing', 0.525831401348114),\n",
              " ('lashins', 0.5253284573554993),\n",
              " ('graywacke', 0.5226282477378845),\n",
              " ('genophobia', 0.5201941728591919)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Word analogies\n",
        "\n",
        "Another interesting property of word embeddings is their ability to capture word analogies through geometric relationships in the vector space. This phenomenon is often illustrated by the famous example: \"king\" - \"man\" + \"woman\" ≈ \"queen\". In this case, the embeddings capture the relationship between gender roles and royal titles.\n",
        "\n",
        "With the help of the previous function, create a the vector queen by using appling the relation (\"king\"-\"man\") to \"woman\".\n",
        "\n"
      ],
      "metadata": {
        "id": "WNuiDqt90MLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def word_analogy(token_a, token_b, token_c):\n",
        "  \"\"\"\n",
        "  Performs vec_token_a - vec_token_b + vec_token_c\n",
        "\n",
        "  and returns a list with the closest tokens\n",
        "\n",
        "  Note: token_a, token_b and token_c should be removed of the list\n",
        "\n",
        "  Example:\n",
        "  word_analogy(\"king\", \"man\", \"woman\")\n",
        "  [('queen', 0.6244865655899048),\n",
        " ('kings', 0.4600622057914734),\n",
        " ('prince', 0.42849528789520264),\n",
        " ('princess', 0.42579346895217896),\n",
        " ('royal', 0.41185224056243896),\n",
        " ('crown', 0.4051671624183655),\n",
        " ('princes', 0.40045303106307983),\n",
        " ('lamb', 0.3960754871368408),\n",
        " ('hamilton', 0.39465370774269104)]\n",
        "  \"\"\"\n",
        "  ## Complete\n",
        "\n",
        "  # get emb for token_a token_b token_c\n",
        "\n",
        "  # approx_vec = emb_a - emb_b + emb_c\n",
        "\n",
        "  # return find(approx_vec)\n",
        "\n",
        "\n",
        "\n",
        "  approx_vec =  in_embeddings[in_token_to_id[token_a]] - in_embeddings[in_token_to_id[token_b]] + in_embeddings[in_token_to_id[token_c]]\n",
        "  # approx_vec is not normalized\n",
        "  approx_vec = approx_vec/torch.linalg.norm(approx_vec, ord=2)\n",
        "\n",
        "  top_results = find_topk_similar_to_vec(approx_vec, in_embeddings, in_token_to_id, in_id_to_token)\n",
        "\n",
        "  # remove token_a, token_b and token_c from the list\n",
        "  exclude = {token_a, token_b, token_c}\n",
        "  return [(tk,score) for tk, score in top_results if tk not in exclude]\n",
        "\n",
        "word_analogy(\"king\", \"man\", \"woman\") # expected queen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHbbnNM91uS2",
        "outputId": "1ac9d1f8-3d97-4080-fc87-ecc1e26af439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.6244865655899048),\n",
              " ('kings', 0.4600622057914734),\n",
              " ('prince', 0.42849528789520264),\n",
              " ('princess', 0.42579346895217896),\n",
              " ('royal', 0.41185224056243896),\n",
              " ('crown', 0.4051671624183655),\n",
              " ('princes', 0.40045303106307983),\n",
              " ('lamb', 0.3960754871368408),\n",
              " ('hamilton', 0.39465370774269104)]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_analogy(\"paris\", \"france\", \"portugal\") # expected lisbon"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5J2bm1d22fo",
        "outputId": "3ee7f928-48ee-4b0c-ecf2-3fd4e9f556c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('lisbon', 0.5874060988426208),\n",
              " ('barcelona', 0.5461090207099915),\n",
              " ('porto', 0.512915849685669),\n",
              " ('malaga', 0.5048376321792603),\n",
              " ('rambla', 0.49051910638809204),\n",
              " ('vila', 0.4781612753868103),\n",
              " ('quito', 0.4775787889957428),\n",
              " ('oporto', 0.47215747833251953)]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_analogy(\"france\", \"paris\", \"lisbon\") # expected portugal"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTHcYyJa3tQk",
        "outputId": "00cbc214-5c56-4f2b-f5bb-1613deaebbf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('portugal', 0.6427342295646667),\n",
              " ('poland', 0.5291943550109863),\n",
              " ('austria', 0.5101706385612488),\n",
              " ('germany', 0.4979320466518402),\n",
              " ('netherlands', 0.49458247423171997),\n",
              " ('azores', 0.4933825731277466),\n",
              " ('lithuania', 0.4896232485771179),\n",
              " ('spain', 0.4859029948711395)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_analogy(\"teacher\", \"school\", \"hospital\") # expected ? (maybe doctor?)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YonYWmzB-jAv",
        "outputId": "a816d309-7300-49a1-e5d9-da79f13d2e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('nurse', 0.6128870248794556),\n",
              " ('physician', 0.5838133096694946),\n",
              " ('therapist', 0.5681063532829285),\n",
              " ('hospita', 0.5670239329338074),\n",
              " ('pharmacist', 0.5632860660552979),\n",
              " ('midwives', 0.5558406710624695),\n",
              " ('nurses', 0.5456812381744385),\n",
              " ('psychiatrist', 0.5454483032226562),\n",
              " ('hospitals', 0.5374904274940491)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Okey, but if I want to use sentance or documents?\n",
        "\n",
        "In such scenarios, a straightforward approach is to average the embeddings of all tokens within a sentence. This method offers a means to condense the rich information of a sentence into a single vector.\n",
        "\n",
        "By averaging the embeddings of each word in a sentence, we create a composite representation that captures the essence of the sentence as a whole. This can then be used to compare and measure the similarity between different sentences or documents. It's a practical method, especially when dealing with small texts. Let's proceed to implement this and see how well it performs in identifying sentence similarities."
      ],
      "metadata": {
        "id": "NtTcrOmL4FE3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_corpus = [\n",
        "    \"A nimble red fox leaped over a sleeping canine.\",\n",
        "    \"New York is known for its bustling city life.\",\n",
        "    \"The city of Tokyo is lively and vibrant at night.\",\n",
        "    \"The development of AI has significant implications for society.\",\n",
        "    \"Fresh vegetables and fruits are essential for a healthy diet.\",\n",
        "    \"Eating a variety of greens and fruits contributes to good health.\",\n",
        "    \"The book on the shelf is old and worn.\",\n",
        "    \"An ancient, tattered tome sits in the library.\"\n",
        "]\n",
        "\n",
        "sentence_to_id = {s:i for i,s in enumerate(sentences_corpus)}\n",
        "id_to_sentence = sentences_corpus\n",
        "#id_to_sentence = {v:k for k,v in sentence_to_id.items()}"
      ],
      "metadata": {
        "id": "R3ThKFWT4EHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def text_to_vec(text, embeddings, in_token_to_id):\n",
        "  # simple tokenizer\n",
        "  tokens = text.lower().split() # [list of tokens]\n",
        "\n",
        "  # lista das embeddings dos tokens que estao no V\n",
        "  return [embeddings[in_token_to_id[token]] for token in tokens if token in in_token_to_id]\n",
        "\n",
        "def sentence_embedding(text, embeddings):\n",
        "  \"\"\"\n",
        "  Give a sequence of text compute the embeddings of the sentece by averaging its token embeddings\n",
        "\n",
        "  use the function text_to_vec to convert text to vectors: text_to_vec(text, embeddings, in_token_to_id)\n",
        "\n",
        "  Out: sentence embeddings\n",
        "  \"\"\"\n",
        "  ## Complete\n",
        "\n",
        "  tokens_emb = torch.stack(text_to_vec(text, embeddings, in_token_to_id)) # [vec_a, vac_b, vac_c ...]\n",
        "  # [vec_a,\n",
        "  #  vec_b,\n",
        "  #   vec_c,] T x 200\n",
        "\n",
        "  sent_emb = tokens_emb.mean(axis=0)# 200\n",
        "\n",
        "  return sent_emb / torch.linalg.norm(sent_emb, ord=2)\n",
        "\n",
        "# [sentence_embedding(sent, in_embeddings) for sent in sentences_corpus] lista da embbedings de cada frase\n",
        "sentences_corpus_embeddings = torch.stack([sentence_embedding(sent, in_embeddings) for sent in sentences_corpus])\n",
        "# S x 200\n"
      ],
      "metadata": {
        "id": "GUrhIkHC6SXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences_corpus_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RceQCSgeuHR-",
        "outputId": "726f930d-5432-4ca1-809b-7f28ff995195"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_embedding = sentence_embedding(\"Artificial Intelligence will shape the future of humanity.\", in_embeddings)\n",
        "find_topk_similar_to_vec(sent_embedding, sentences_corpus_embeddings, sentence_to_id, id_to_sentence, topk=5)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOz00Zzv61Pa",
        "outputId": "77a82424-5cbf-44fa-f3e2-d400f12c5a01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The development of AI has significant implications for society.',\n",
              "  0.8642897605895996),\n",
              " ('Eating a variety of greens and fruits contributes to good health.',\n",
              "  0.8398697972297668),\n",
              " ('The book on the shelf is old and worn.', 0.8192300796508789),\n",
              " ('The city of Tokyo is lively and vibrant at night.', 0.77782142162323),\n",
              " ('Fresh vegetables and fruits are essential for a healthy diet.',\n",
              "  0.7680155038833618)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_embedding = sentence_embedding(\"The quick brown fox jumps over the lazy dog.\", in_embeddings)\n",
        "find_topk_similar_to_vec(sent_embedding, sentences_corpus_embeddings, sentence_to_id, id_to_sentence, topk=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQyoefdtByET",
        "outputId": "6aeabc77-4852-4282-b1db-6700d3af973d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('A nimble red fox leaped over a sleeping canine.', 0.8499789237976074),\n",
              " ('The book on the shelf is old and worn.', 0.8179973363876343),\n",
              " ('The city of Tokyo is lively and vibrant at night.', 0.7329216003417969),\n",
              " ('An ancient, tattered tome sits in the library.', 0.7195178866386414),\n",
              " ('Eating a variety of greens and fruits contributes to good health.',\n",
              "  0.6892918348312378)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Well if it works for sentence similarity, maybe it works for retrieval?\n",
        "\n",
        "Let's apply the same example to this toy collection of documents"
      ],
      "metadata": {
        "id": "d3Iu4FOHD59C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    \"Apples are rich in antioxidants, which help in fighting free radicals.\",\n",
        "    \"The water cycle consists of evaporation, condensation, and precipitation.\",\n",
        "    \"Recent trends in AI include advancements in deep learning and neural networks.\",\n",
        "    \"Good mental health can be maintained by regular exercise and proper sleep.\",\n",
        "    \"The Olympic Games originated in ancient Greece and have evolved over centuries.\",\n",
        "    \"Eating fruits and vegetables is essential for physical well-being.\",\n",
        "    \"Cloud formation is a key aspect of the earth's hydrological process.\",\n",
        "    \"Machine learning and AI are becoming integral in various industries.\",\n",
        "    \"Mindfulness and meditation are effective for stress management.\",\n",
        "    \"The modern Olympics include a variety of sports from track to swimming.\"\n",
        "]\n",
        "\n",
        "doc_to_id = {s:i for i,s in enumerate(documents)}\n",
        "id_to_doc = documents\n",
        "\n",
        "doc_embeddings = torch.stack([sentence_embedding(sent, in_embeddings) for sent in documents])\n",
        "doc_embeddings.shape"
      ],
      "metadata": {
        "id": "vLRFmGr3EHLi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd6b87fe-bddd-47eb-c831-7539ef59b201"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_embedding = sentence_embedding(\"How does the water cycle work?\", in_embeddings)\n",
        "find_topk_similar_to_vec(sent_embedding, doc_embeddings, doc_to_id, id_to_doc, topk=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpG3dbVGEKgg",
        "outputId": "c16d800d-e103-49b9-d259-aaee4a06c10f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The water cycle consists of evaporation, condensation, and precipitation.',\n",
              "  0.7694262266159058),\n",
              " (\"Cloud formation is a key aspect of the earth's hydrological process.\",\n",
              "  0.5853888392448425),\n",
              " ('Eating fruits and vegetables is essential for physical well-being.',\n",
              "  0.5655031204223633)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent_embedding = sentence_embedding(\"What is the history of the Olympic Games?\", in_embeddings)\n",
        "find_topk_similar_to_vec(sent_embedding, doc_embeddings, doc_to_id, id_to_doc, topk=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etuSTaFMEzLk",
        "outputId": "3958995c-93cd-4a6f-e690-e13a7b22bcb4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The modern Olympics include a variety of sports from track to swimming.',\n",
              "  0.9072824716567993),\n",
              " ('The Olympic Games originated in ancient Greece and have evolved over centuries.',\n",
              "  0.886823296546936),\n",
              " (\"Cloud formation is a key aspect of the earth's hydrological process.\",\n",
              "  0.8800275921821594)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DESM model\n",
        "\n",
        "Up to this point, we have primarily utilized the 'IN' embeddings of the DESM (Dual Embedding Space Model) model. Let's delve deeper into understanding and exploring this model:\n",
        "\n",
        "The DESM model is unique in its dual-embedding approach. It leverages both 'IN' and 'OUT' embeddings to enhance the representation of words and phrases.\n",
        "\n",
        "First lets load the OUT embeddings"
      ],
      "metadata": {
        "id": "L7lSSpKqRiwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# note that out_token_to_id and out_id_to_token should be exactly the same as in_token_id and in_id_to_token\n",
        "out_token_to_id, out_id_to_token, out_embeddings = load_embeddings_from_txt(\"out.txt\", vocab_set)\n"
      ],
      "metadata": {
        "id": "SEbammvH-qIr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "480b18d9-97c2-4b10-f661-083d3e64cd4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2748230it [01:19, 34395.88it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In continuation of what we've learned in class, we'll now calculate similarities using different combinations of embeddings from the DESM model. Namely, IN-IN, IN-OUT and OUT-OUT."
      ],
      "metadata": {
        "id": "WLjYNG7tGf5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def in_out_comparison_for_token(token, topk=10):\n",
        "\n",
        "  in_in_results = find_topk_similar_to(token, in_embeddings, in_token_to_id, in_id_to_token, topk=topk)\n",
        "  out_out_results = find_topk_similar_to(token, out_embeddings, out_token_to_id, out_id_to_token, topk=topk)\n",
        "  in_out_results = find_topk_similar_to_vec(in_embeddings[in_token_to_id[token]], out_embeddings, in_token_to_id, in_id_to_token, topk=topk)\n",
        "  print(f'|{\"IN-IN\":^25}|{\"OUT-OUT\":^25}|{\"IN-OUT\":^25}|')\n",
        "  for i in range(topk):\n",
        "    in_in_str = f'{in_in_results[i][0]} ({in_in_results[i][1]:.3f})'\n",
        "    out_out_str = f\"{out_out_results[i][0]} ({out_out_results[i][1]:.3f})\"\n",
        "    in_out_str = f\"{in_out_results[i][0]} ({in_out_results[i][1]:.3f})\"\n",
        "    print(f'|{in_in_str:^25}|{out_out_str:^25}|{in_out_str:^25}|')\n",
        "\n"
      ],
      "metadata": {
        "id": "uF4yZ-_IY75g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "in_out_comparison_for_token(\"yale\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3VWtv2pPHjL",
        "outputId": "00016304-13de-4a7d-fc08-24ec7310dd51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|          IN-IN          |         OUT-OUT         |         IN-OUT          |\n",
            "|      yale (1.000)       |      yale (1.000)       |      yale (0.279)       |\n",
            "|     harvard (0.638)     |     harvard (0.751)     |     faculty (0.187)     |\n",
            "|     cornell (0.610)     |      tufts (0.742)      |     alumni (0.170)      |\n",
            "|   quinnipiac (0.607)    |     cornell (0.738)     | preregistration (0.164) |\n",
            "|      tufts (0.581)      |  northwestern (0.718)   |   orientation (0.164)   |\n",
            "|      emory (0.564)      |   quinnipiac (0.716)    |      haven (0.162)      |\n",
            "|     hamline (0.551)     |    villanova (0.715)    |    graduate (0.156)     |\n",
            "|    stanford (0.549)     |      emory (0.712)      |   admissions (0.156)    |\n",
            "|    villanova (0.531)    |     vassar (0.711)      |    academic (0.155)     |\n",
            "|  northwestern (0.521)   |       uva (0.705)       |      dorms (0.150)      |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "in_out_comparison_for_token(\"apple\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfro6VLBPHlg",
        "outputId": "b6cbaf99-985f-4e1f-b4a1-777469b52383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|          IN-IN          |         OUT-OUT         |         IN-OUT          |\n",
            "|      apple (1.000)      |      apple (1.000)      |      apple (0.246)      |\n",
            "|   blackberry (0.653)    |  misapprehend (0.817)   |     apples (0.167)      |\n",
            "|     apples (0.612)      |     echards (0.817)     |   blackberry (0.161)    |\n",
            "|       mac (0.542)       |     apples (0.814)      |     orchard (0.141)     |\n",
            "|    raspberry (0.535)    |     lattins (0.811)     |      cider (0.140)      |\n",
            "|      cider (0.526)      |     appale (0.809)      |    orchards (0.137)     |\n",
            "|   chokecherry (0.523)   |    cankered (0.807)     |      crisp (0.134)      |\n",
            "|    blueberry (0.496)    |     cobnuts (0.807)     |   pollination (0.130)   |\n",
            "|     crouton (0.496)     |    mesropian (0.805)    |     picking (0.129)     |\n",
            "|     pumpkin (0.495)     |     thistly (0.805)     |    jailbreak (0.113)    |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DESM Retrieval\n",
        "\n",
        "Following the slides lets implement the DESM retrieval model\n",
        "\n",
        "$DESM(Q, D) = \\frac{1}{|Q|}\\sum_{q_i \\in Q}cos(q_i,D)$"
      ],
      "metadata": {
        "id": "_GK1dA25Lasl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    \"Apples are rich in antioxidants, which help in fighting free radicals.\",\n",
        "    \"The water cycle consists of evaporation, condensation, and precipitation.\",\n",
        "    \"Recent trends in AI include advancements in deep learning and neural networks.\",\n",
        "    \"Good mental health can be maintained by regular exercise and proper sleep.\",\n",
        "    \"The Olympic Games originated in ancient Greece and have evolved over centuries.\",\n",
        "    \"Eating fruits and vegetables is essential for physical well-being.\",\n",
        "    \"Cloud formation is a key aspect of the earth's hydrological process.\",\n",
        "    \"Machine learning and AI are becoming integral in various industries.\",\n",
        "    \"Mindfulness and meditation are effective for stress management.\",\n",
        "    \"The modern Olympics include a variety of sports from track to swimming.\"\n",
        "]\n",
        "\n"
      ],
      "metadata": {
        "id": "2RTb5oraPHn2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def desm(query, documents, topk=3):\n",
        "  \"\"\"\n",
        "  Implement the desm algorithm\n",
        "  query: text of a question (use emb IN)\n",
        "  documents: list of documents text that make the collection (use emb OUT)\n",
        "  topk: maximum number of documents that we want to return\n",
        "\n",
        "  desm(\"How does the water cycle work?\", documents)\n",
        "  [('The water cycle consists of evaporation, condensation, and precipitation.',\n",
        "  -0.0023205685429275036),\n",
        " (\"Cloud formation is a key aspect of the earth's hydrological process.\",\n",
        "  -0.028624113649129868),\n",
        " ('Good mental health can be maintained by regular exercise and proper sleep.',\n",
        "  -0.031198585405945778)]\n",
        "  \"\"\"\n",
        "  ## COMPLETE\n",
        "\n",
        "\n",
        "  # average embeddings for the doc\n",
        "  doc_to_id = {s:i for i,s in enumerate(documents)}\n",
        "  id_to_doc = documents\n",
        "\n",
        "  # vec doc in OUT projection\n",
        "  doc_embeddings = torch.stack([sentence_embedding(sent, out_embeddings) for sent in documents])\n",
        "  # 10 x 200\n",
        "\n",
        "  query_token_vecs = torch.stack(text_to_vec(query, in_embeddings, in_token_to_id))\n",
        "  # T x 200\n",
        "\n",
        "  scores_per_token = query_token_vecs @ doc_embeddings.T # Tx10\n",
        "  # 10 -> cos(q, D)\n",
        "\n",
        "  scores = scores_per_token.mean(axis=0)\n",
        "\n",
        "  ordered_scores, ordered_ids = torch.topk(scores, k= topk)\n",
        "\n",
        "  return list(map(lambda x: (id_to_doc[x[0].item()], x[1].item()), zip(ordered_ids, ordered_scores)))\n",
        "\n"
      ],
      "metadata": {
        "id": "O3IB_hjpMMb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "desm(\"How does the water cycle work?\", documents) # it help?\n"
      ],
      "metadata": {
        "id": "caldWOHaPHqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45f30b0d-0e15-426a-8bd3-91505b5315b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The water cycle consists of evaporation, condensation, and precipitation.',\n",
              "  -0.0023205664474517107),\n",
              " (\"Cloud formation is a key aspect of the earth's hydrological process.\",\n",
              "  -0.02862410619854927),\n",
              " ('Good mental health can be maintained by regular exercise and proper sleep.',\n",
              "  -0.03119858168065548)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "desm(\"What is the history of the Olympic Games?\", documents)"
      ],
      "metadata": {
        "id": "J2ChqVTCPHsk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c050c4a-89cb-49a9-a59d-9b33dfbfb594"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The Olympic Games originated in ancient Greece and have evolved over centuries.',\n",
              "  -0.014345861971378326),\n",
              " ('The water cycle consists of evaporation, condensation, and precipitation.',\n",
              "  -0.023791415616869926),\n",
              " (\"Cloud formation is a key aspect of the earth's hydrological process.\",\n",
              "  -0.023795852437615395)]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SzpHPcwWPHuq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MTWondNZPHxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hsSXU6TyPHz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Iwqx3xwiNVo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TlxMGWQWly2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LJO99y0HNV_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jbiTPZT-NsbX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7NQ-ypyCNvdz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}