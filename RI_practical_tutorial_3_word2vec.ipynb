{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2Fik5GABqLZ6guz0WNosn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ua-deti-information-retrieval/Neural-IR-hands-on/blob/main/RI_practical_tutorial_3_word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RI practical tutorial #3\n",
        "\n",
        "## Word2Vec\n",
        "\n",
        "Now that we have explored the usefulness of embeddings, the next question is: how can we learn such useful representations?\n",
        "\n",
        "Mikolov et al. proposed two main algorithms, CBOW (Continuous Bag of Words) and Skip-Gram, both based on a similar concept: leveraging the co-occurrence of words to learn meaningful spatial mappings.\n",
        "\n",
        "These methods use the surrounding context of words in a corpus to train the model, thus capturing the semantic relationships between them effectively.\n"
      ],
      "metadata": {
        "id": "WEzDVxR_GS_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependencies"
      ],
      "metadata": {
        "id": "HTM0S306OL5a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7KLH66SGHFk",
        "outputId": "1498b884-6e8f-4711-a982-d34517bb659a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Cloning into 'Neural-IR-hands-on'...\n",
            "remote: Enumerating objects: 25, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 25 (delta 9), reused 8 (delta 1), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (25/25), 3.08 MiB | 11.11 MiB/s, done.\n",
            "Resolving deltas: 100% (9/9), done.\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!git clone https://github.com/ua-deti-information-retrieval/Neural-IR-hands-on.git\n",
        "!cd Neural-IR-hands-on"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget \"https://uapt33090-my.sharepoint.com/:u:/g/personal/aleixomatos_ua_pt/EWmWvPAkGq9Eq1RbL4C9uiYBDLEZqg6LRflxkMx52zvX1g?e=kBFkOY&download=1\" -O pubmed_2022_tiny.jsonl.gz\n",
        "!gzip -d pubmed_2022_tiny.jsonl.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjaL7QFoe80e",
        "outputId": "7916128f-fc85-4fb3-dec6-629e7976455a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-11-29 00:31:36--  https://uapt33090-my.sharepoint.com/:u:/g/personal/aleixomatos_ua_pt/EWmWvPAkGq9Eq1RbL4C9uiYBDLEZqg6LRflxkMx52zvX1g?e=kBFkOY&download=1\n",
            "Resolving uapt33090-my.sharepoint.com (uapt33090-my.sharepoint.com)... 13.107.136.10, 13.107.138.10, 2620:1ec:8f8::10, ...\n",
            "Connecting to uapt33090-my.sharepoint.com (uapt33090-my.sharepoint.com)|13.107.136.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /personal/aleixomatos_ua_pt/Documents/@UA/Aulas/RI/2023/Dossier/Data/pubmed_2022_tiny.jsonl.gz?ga=1 [following]\n",
            "--2023-11-29 00:31:37--  https://uapt33090-my.sharepoint.com/personal/aleixomatos_ua_pt/Documents/@UA/Aulas/RI/2023/Dossier/Data/pubmed_2022_tiny.jsonl.gz?ga=1\n",
            "Reusing existing connection to uapt33090-my.sharepoint.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 134376760 (128M) [application/x-gzip]\n",
            "Saving to: ‘pubmed_2022_tiny.jsonl.gz’\n",
            "\n",
            "pubmed_2022_tiny.js 100%[===================>] 128.15M  36.5MB/s    in 3.7s    \n",
            "\n",
            "2023-11-29 00:31:41 (35.0 MB/s) - ‘pubmed_2022_tiny.jsonl.gz’ saved [134376760/134376760]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset, IterableDataset\n",
        "from itertools import chain\n",
        "import torch\n",
        "import random\n",
        "\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "from collections import defaultdict\n",
        "import math\n",
        "\n",
        "import json\n"
      ],
      "metadata": {
        "id": "E5CGinJe1IBh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hands on!\n"
      ],
      "metadata": {
        "id": "HnYRQPKWORgd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model\n",
        "\n",
        "[![Alt text](https://miro.medium.com/v2/resize:fit:1400/1*cuOmGT7NevP9oJFJfVpRKA.png)](https://miro.medium.com/v2/resize:fit:1400/1*cuOmGT7NevP9oJFJfVpRKA.png)"
      ],
      "metadata": {
        "id": "fSYoCaE5ferj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Tokenizer"
      ],
      "metadata": {
        "id": "SpjnbI_xff28"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### DataLoader"
      ],
      "metadata": {
        "id": "rx-5PO5rfiGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training loop"
      ],
      "metadata": {
        "id": "m6ScRvfhfkhj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AF4Z4OJzfdtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FWQGAEJAlMX3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ApSIqDxl2BDt"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}